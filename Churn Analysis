library(caret)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tidyverse)


telco <-read.csv("D:/RIZA/telco.csv",header=T,sep=";")
telco$broadband_rev <-as.numeric(telco$broadband_rev)
telco$broadband_usg <-as.numeric(telco$broadband_usg)
telco$voice_rev <-as.numeric(telco$voice_rev)
telco$lapsed_flag <- ifelse (telco$lapsed_flag == 0, "aktif", "churn")
telco$lapsed_flag <- as.factor(telco$lapsed_flag)

library(ggcorrplot)
library(ggplot2)
#corr <- cor(telco[,-c(1,5,12,13)])
corr <- cor(telco,method="spearman")
corr
ggcorrplot(corr, hc.order = T,method="spearman",
           type = "lower", 
           lab = TRUE, 
           lab_size = 2.5, 
           method="circle", 
           colors = c("tomato2", "white", "springgreen3"), 
           title="Correlation data", 
           ggtheme=theme_bw)

View(telco)
summary(telco)
colnames(telco)
str(telco)
is.data.frame(telco)
sum(is.na(telco))

telco.baru <- scale(telco[,-18])
View(telco.baru)
colnames(telco.baru)
tel <-as.data.frame(telco.baru)
is.data.frame(tel)

par(mfrow=c(2,2))
boxplot(telco$los,main="LOS")
boxplot(telco$rchg_rev,main="RCHG REV")
boxplot(telco$voice_rev,main="VOICE REV")
boxplot(telco$sms_rev,main="SMS REV")
boxplot(telco$broadband_rev,main="BROADBAND REV")
boxplot(telco$voice_package_rev,main="VOICE PACKAGE REV")
boxplot(telco$rchg_trx,main="RCHG TRX")
boxplot(telco$voice_trx,main="VOICE TRX")
boxplot(telco$sms_trx,main="SMS TRX")
boxplot(telco$voice_mou,main="VOICE MOU")
boxplot(telco$voice_dou,main="VOICE DOU")
boxplot(telco$sms_dou,main="SMS DOU")
boxplot(telco$voice_package_dou,main="VOICE PACKAGE DOU")
boxplot(telco$broadband_dou,main="BROADBAND DOU")
boxplot(telco$broadband_usg,main="BROADBAND USG")
boxplot(telco$voice_package_trx,main="VOICE PACKAGE USG")

#iseng korelasi y dengan x tapi gak bisa
corr <- cor(telco$los,telco$lapsed_flag,method="spearman")
method = c("pearson", "kendall", "spearman"))

set.seed(2020)
index_train2=createDataPartition(telco$lapsed_flag, p=0.8, list=FALSE)
train=telco[index_train2,]
test=telco[-index_train2,]
nrow(train)
nrow(test)
head(train)

#RAMDOM FOREST
library(randomForest)
library(rpart)
library(rpart.plot)
library(caret)
library(dplyr)
library(purrr)
library(rattle)
library(devtools)
library(reprtree)
rf=randomForest(lapsed_flag~voice_mou+voice_trx+voice_package_dou+
voice_package_rev+los+voice_package_trx+sms_trx+voice_rev,
                     data=train,
                     ntree=500)
prediksi.pohon=predict(rf, test)
confusionMatrix(prediksi.pohon,test$lapsed_flag)
plot(rf)
getTree(rf, 1, labelVar=TRUE)
reprtree:::plot.getTree(rf,1)
varImp(rf)

set.seed(2020)
#melakukan undersampling
down_train <- downSample(x = train[, -ncol(train)],y = train$lapsed_flag)
#pemodelan RF menggunakan data hasil undersampling 
model.rf.under<- randomForest(Class~voice_mou+voice_trx+voice_package_dou+
voice_package_rev+los+voice_package_trx+sms_trx+voice_rev,data=down_train, importance=TRUE, ntree=50, mtry=8)
### mtry=8, berarti hanya 8 variabel yang dipilih
pred.rf.under<- predict(model.rf.under, test)
#mengevaluasi ketepatan prediksi dari model 
eval.under<-confusionMatrix(pred.rf.under, test$lapsed_flag) 
eval.under

#melakukan oversampling
up_train <- upSample(x = train[, -ncol(train)],y = train$lapsed_flag)
#pemodelan RF menggunakan data hasil oversampling 
model.rf.over<- randomForest(Class~voice_mou+voice_trx+voice_package_dou+
voice_package_rev+los+voice_package_trx+sms_trx+voice_rev,data=up_train, importance=TRUE, ntree=50, mtry=8)
### mtry=8, berarti hanya 8 variabel yang dipilih
pred.rf.over<- predict(model.rf.under, test)
#mengevaluasi ketepatan prediksi dari model 
eval.over<-confusionMatrix(pred.rf.over, test$lapsed_flag) 
eval.over

folds = createFolds(train$lapsed_flag, k = 5)
cv = lapply(folds, function(x) { 
	#index_train2=createDataPartition(telco$lapsed_flag, p=0.8, list=FALSE)
	#train=telco[index_train2,]
	#test=telco[-index_train2,]
  training_fold = telco[-x, ] 
  test_fold = telco[x, ] 
  classifier = randomForest(lapsed_flag~voice_mou+voice_trx+voice_package_dou+
			voice_package_rev+los+voice_package_trx+sms_trx+voice_rev,
                   data=train,method="class",
                   ntree=50)
  y_pred = predict(classifier, newdata = test_fold)
  cm = table(test_fold, y_pred)
  accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  return(accuracy)
})

knitr::include_graphics("cv.png")



#POHON KLASIFIKASI
library(rpart)
library(rpart.plot)
tree=rpart(lapsed_flag~voice_mou+voice_trx+voice_package_dou+
			voice_package_rev+los+voice_package_trx+sms_trx+voice_rev,
data=train,method="class")

prediksi.tree <- predict(tree, test)
prediksi <- ifelse (prediksi.tree[,2] > 0.5, "1", "0")
table(test$lapsed_flag, prediksi)
(10756+3024)/17999

confusionMatrix(as.factor(prediksi),test$lapsed_flag)
rpart.plot(tree)

akurasi <- NULL
a <- seq(1, 100, by=2)

for (k in a){
    model = rpart(lapsed_flag~voice_mou+voice_trx+voice_package_dou+
voice_package_rev+los+voice_package_trx+sms_trx+voice_rev+sms_dou+voice_dou,
data = train, method="class",control = rpart.control(minsplit = k, cp = 0))
    y=predict(model,test,type="class")
  akurasi[k]=mean(ifelse(y==test$lapsed_flag,1,0))*100
  }

akurasi1=data.frame(a,akurasi[complete.cases(akurasi)])
kmax=akurasi1[akurasi1$akurasi==max(akurasi[complete.cases(akurasi)]),1]
cat("nilai terbaik adalah :",kmax,'\n')
cat('kekuatan akurasi:',akurasi[kmax],'\n')
plot(akurasi1,kmax,type="b",pch=19,ylab="Akurasi",main="Jumlah Minsplit Optimal")


## LOGISTIK
library(class)
model.reglog=glm(lapsed_flag~los+voice_rev+voice_trx+voice_mou+voice_package_trx+
                      +voice_package_dou+voice_package_rev+sms_trx,
                 data=train,family = 'binomial')
summary(model.reglog)

prediksi=predict.glm(model.reglog,test,type = 'response')
prediksi

insidence.rate=mean(train$lapsed_flag=='1')
#mengkategorikan prediksi peluang dg cut off=incidense rate
kelas.prediksi=ifelse(prediksi>insidence.rate,"1","0")
table(test$lapsed_flag,kelas.prediksi)
nrow(kelas.prediksi)
#Akurasi
confusionMatrix(as.factor(kelas.prediksi),test$lapsed_flag,positive="0")

#kurva ROC
library(pROC)
roc.log<-roc(test$lapsed_flag,prediksi)
auc(roc.log)
plot.roc(roc.log)

# fit neural network
library(neuralnet)
NN = neuralnet(lapsed_flag~.,
                 data=train, hidden = c(4,2), linear.output = T )
predr<- predict(NN, test)
#mengevaluasi ketepatan prediksi dari model 
eval.over<-confusionMatrix(pred.rf.over, test$y) 
eval.over

# SVM
library(kernlab)      # SVM methodology
library(e1071)        # SVM methodology
svm.r <- svm(lapsed_flag~los+voice_rev+voice_trx+voice_mou+voice_package_trx+
                      +voice_package_dou+voice_package_rev+sms_trx, data=train,
                  type="C-classification",
                  kernel="radial") 
svm.poly
summary(svm)
prediksi.svm=predict(svm, test)
confusionMatrix(prediksi.svm,test$lapsed_flag)
plot(svm.r,train,voice_trx~voice_rev)

svm_tune=tune(svm,lapsed_flag~los+voice_rev+voice_trx+voice_mou+voice_package_trx+
                      +voice_package_dou+voice_package_rev+sms_trx, data = train,
               type="C-classification",
               kernel="radial",ranges = list(cost=c(1,5,10,50,100)))
print(svm_tune)
summary(svm_tune)
svm_tune$best.model

#Boosting
library(ada)
model.boost <- ada(lapsed_flag~., data=train,type="discrete")
prediksii=predict(model.boost,test)
confusionMatrix(prediksii,test$lapsed_flag)

library(caret)
# Define the control
trControl <- trainControl(method = "cv",
                          number = 5)
# Run the model
#nb,rpart,glmboost,lm
library(mboost)
library(klaR)
rf_default <- train(lapsed_flag~los+voice_rev+voice_trx+voice_mou+voice_package_trx+
                      +voice_package_dou+voice_package_rev+sms_trx,
                    data = train,
                    method = "svmRadial",
                    metric = "Accuracy",
                    trControl = trControl)
# Print the results
print(rf_default)

library(xgboost)
dtrain <- xgb.DMatrix(data = train,label = train$lapsed_flag) 
dtest <- xgb.DMatrix(data = test,label=test$lapsed_flag)

dtrain <- xgb.DMatrix(train, label = train$lapsed_flag)
cv <- xgb.cv(data = dtrain, nrounds = 3, nthread = 2, nfold = 5, metrics = list("rmse","auc"),
                  max_depth = 3, eta = 1, objective = "binary:logistic")
print(cv)
print(cv, verbose=TRUE)

model.fit <- rpart(lapsed_flag~los+voice_rev+voice_trx+voice_mou+voice_package_trx+
                      +voice_package_dou+voice_package_rev+sms_trx, data = train, method = 'class',
             control = rpart.control(minsplit = 97, cp = 0.0006992396))
summary(model.fit)
rpart.plot(model.fit, type=0, fallen.leaves=F, cex=0.68,
           box.palette=c("pink", "yellow", "aquamarine"))

